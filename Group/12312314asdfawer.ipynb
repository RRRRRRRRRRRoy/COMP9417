{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "# This is for the COMP9417 Group Project\r\n",
    "# The problem is the OTTO in the Kaggle\r\n",
    "# Source: https://www.kaggle.com/c/otto-group-product-classification-challenge/overview\r\n",
    "# RandomForest / conception / svm / knn / Naive Bayesian"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from sklearn.utils import shuffle\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.svm import LinearSVC\r\n",
    "from sklearn.cluster import KMeans"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "raw_train_data = pd.read_csv(\"D:\\\\train.csv\")\r\n",
    "raw_test_data = pd.read_csv(\"D:\\\\test.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "print(raw_train_data.shape)\r\n",
    "print(raw_test_data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(61878, 95)\n",
      "(144368, 94)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "Train_data = raw_train_data.iloc[:, 1:95]\r\n",
    "labels = set(Train_data.iloc[:,93:94].target)\r\n",
    "Valid_x = np.array(raw_test_data.iloc[:, 1:94])\r\n",
    "Total_x = np.array(Train_data.iloc[:,0:93])\r\n",
    "Total_y = np.array(Train_data.iloc[:,93:94])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "print(f\"The current has the following label {labels}\")\r\n",
    "print(f\"The shape the Total_X {Total_x.shape}\")\r\n",
    "print(f\"The shape the Total_Y {Total_y.shape}\")\r\n",
    "print(f\"The shape the Valid_X {Valid_x.shape}\")\r\n",
    "print(f\"Check Nan in Total_X {set(np.isnan(Total_x).any(axis=1))}\")\r\n",
    "# print(f\"Check Nan in Train_Y {np.isnan(Train_Y).any(axis=1)}\")\r\n",
    "print(f\"Check Nan in Valid_X {set(np.isnan(Valid_x).any(axis=1))}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The current has the following label {'Class_2', 'Class_5', 'Class_9', 'Class_4', 'Class_7', 'Class_3', 'Class_1', 'Class_8', 'Class_6'}\n",
      "The shape the Total_X (61878, 93)\n",
      "The shape the Total_Y (61878, 1)\n",
      "The shape the Valid_X (144368, 93)\n",
      "Check Nan in Total_X {False}\n",
      "Check Nan in Valid_X {False}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "Total_X,Total_Y = shuffle(Total_x,Total_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# In this part using the previous 50000 to do the training and the last data to do the test check the score\r\n",
    "Train_X = Total_X[:50000]\r\n",
    "Train_Y = Total_Y[:50000]\r\n",
    "Test_X = Total_X[50000:]\r\n",
    "Test_Y = Total_Y[50000:]\r\n",
    "print(Train_X.shape)\r\n",
    "print(Train_Y.shape)\r\n",
    "print(Test_X.shape)\r\n",
    "print(Test_Y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000, 93)\n",
      "(50000, 1)\n",
      "(11878, 93)\n",
      "(11878, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.cluster import KMeans"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# The n_neighbors=3 is due to KNeighboursClassifier [k=3]\r\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=9)\r\n",
    "# fit the knn classifier\r\n",
    "knn_classifier.fit(Train_X ,Train_Y.ravel())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=9)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "predict_y = knn_classifier.predict(Test_X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "normal_KNN_report = metrics.classification_report(Test_Y,predict_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "print(normal_KNN_report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class_1       0.65      0.53      0.59       391\n",
      "     Class_2       0.68      0.85      0.76      3109\n",
      "     Class_3       0.55      0.47      0.51      1539\n",
      "     Class_4       0.69      0.24      0.35       551\n",
      "     Class_5       0.93      0.97      0.95       524\n",
      "     Class_6       0.94      0.93      0.94      2654\n",
      "     Class_7       0.75      0.58      0.65       523\n",
      "     Class_8       0.90      0.90      0.90      1601\n",
      "     Class_9       0.85      0.87      0.86       986\n",
      "\n",
      "    accuracy                           0.78     11878\n",
      "   macro avg       0.77      0.70      0.72     11878\n",
      "weighted avg       0.78      0.78      0.77     11878\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# Best C: 0.1\r\n",
    "# Best Score: 0.75044\r\n",
    "best_C = 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "svc = LinearSVC(C=best_C, random_state=0)\r\n",
    "svc.fit(Train_X, Train_Y)\r\n",
    "svm_pred = svc.predict(Test_X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "E:\\Anaconda\\envs\\tf24\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "E:\\Anaconda\\envs\\tf24\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "normal_svm_predict = metrics.classification_report(Test_Y,svm_pred)\r\n",
    "print(normal_svm_predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class_1       0.82      0.17      0.29       391\n",
      "     Class_2       0.64      0.77      0.70      3109\n",
      "     Class_3       0.46      0.45      0.45      1539\n",
      "     Class_4       0.83      0.10      0.18       551\n",
      "     Class_5       0.97      0.96      0.96       524\n",
      "     Class_6       0.92      0.93      0.93      2654\n",
      "     Class_7       0.63      0.62      0.63       523\n",
      "     Class_8       0.86      0.89      0.88      1601\n",
      "     Class_9       0.76      0.89      0.82       986\n",
      "\n",
      "    accuracy                           0.74     11878\n",
      "   macro avg       0.77      0.64      0.65     11878\n",
      "weighted avg       0.75      0.74      0.72     11878\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# XGboost"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "import xgboost as xgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "xgb_train_X = xgb.DMatrix(Train_X)\r\n",
    "pre_num_y = [[int(i[-1][-1])] for i in Train_Y]\r\n",
    "# print(pre_num_y)\r\n",
    "xgb_train_Y = xgb.DMatrix(np.array(pre_num_y))\r\n",
    "Train_Total = xgb.DMatrix(Train_X,pre_num_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "xgb_classifier = xgb.XGBClassifier(n_estimators=93,\\\r\n",
    "                                   max_depth=4, \\\r\n",
    "                                   learning_rate=0.1, \\\r\n",
    "                                   subsample=0.7, \\\r\n",
    "                                   colsample_bytree=0.7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "X_test = xgb.DMatrix(Test_X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "params = {\"objective\": \"multi:softprob\", \"eval_metric\":\"mlogloss\", \"num_class\": 9}\r\n",
    "xgb_classifier.train(params,Train_Total,180)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'train'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-487b4fa0c4d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"multi:softprob\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"eval_metric\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"mlogloss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_class\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxgb_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTrain_Total\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'train'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds_xgb = xgb_classifier.predict(Test_X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "normal_xgb_predict = metrics.classification_report(Test_Y,preds_xgb)\r\n",
    "print(normal_svm_predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class_1       0.66      0.25      0.36       387\n",
      "     Class_2       0.60      0.92      0.73      3084\n",
      "     Class_3       0.53      0.24      0.33      1546\n",
      "     Class_4       0.89      0.11      0.20       552\n",
      "     Class_5       0.96      0.94      0.95       521\n",
      "     Class_6       0.91      0.92      0.92      2646\n",
      "     Class_7       0.75      0.52      0.61       582\n",
      "     Class_8       0.86      0.90      0.88      1654\n",
      "     Class_9       0.81      0.85      0.83       906\n",
      "\n",
      "    accuracy                           0.74     11878\n",
      "   macro avg       0.78      0.63      0.64     11878\n",
      "weighted avg       0.75      0.74      0.71     11878\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kmeans = KMeans(n_clusters=9, random_state=0).fit(Train_X,Train_Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kmns_pred = kmeans.predict(Test_X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result_pred_kmns = [[f\"Class_{i}\"] for i in kmns_pred]\r\n",
    "# print(result_pred_kmns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "KMNS_REPORT = metrics.classification_report(Test_Y,result_pred_kmns)\r\n",
    "print(KMNS_REPORT)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class_0       0.00      0.00      0.00         0\n",
      "     Class_1       0.00      0.00      0.00       387\n",
      "     Class_2       0.00      0.00      0.00      3084\n",
      "     Class_3       0.00      0.00      0.00      1546\n",
      "     Class_4       0.00      0.00      0.00       552\n",
      "     Class_5       0.01      0.01      0.01       521\n",
      "     Class_6       0.00      0.00      0.00      2646\n",
      "     Class_7       0.00      0.00      0.00       582\n",
      "     Class_8       0.21      0.10      0.14      1654\n",
      "     Class_9       0.00      0.00      0.00       906\n",
      "\n",
      "    accuracy                           0.01     11878\n",
      "   macro avg       0.02      0.01      0.01     11878\n",
      "weighted avg       0.03      0.01      0.02     11878\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "E:\\Anaconda\\envs\\tf24\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\envs\\tf24\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\envs\\tf24\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\envs\\tf24\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\envs\\tf24\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\envs\\tf24\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tf24': conda)"
  },
  "interpreter": {
   "hash": "fc41597814ff85e0caced484d48bad3e0926c3d440aa194648a264b83f287c05"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}